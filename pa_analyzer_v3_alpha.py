"""
Live PA Audio Analyzer V3.0 Alpha
- å‘¨æ³¢æ•°ãƒ™ãƒ¼ã‚¹éŸ³æºåˆ†é›¢
- æ¥½å™¨åˆ¥è©³ç´°è§£æ
- è¶…è©³ç´°ãªæ”¹å–„ææ¡ˆ

Usage:
    streamlit run pa_analyzer_v3_alpha.py
"""

import streamlit as st
import numpy as np
import librosa
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from scipy import signal
from scipy.stats import pearsonr
import io
from pathlib import Path
import tempfile
import json
from datetime import datetime

# matplotlibã®è¨­å®š
plt.rcParams['figure.max_open_warning'] = 50
plt.rcParams['font.size'] = 10

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Live PA Audio Analyzer V3.0",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        margin-bottom: 1rem;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    .version-badge {
        text-align: center;
        color: #667eea;
        font-weight: bold;
        margin-bottom: 2rem;
    }
    .instrument-card {
        background-color: #f8f9fa;
        padding: 1.5rem;
        border-radius: 0.5rem;
        border-left: 4px solid #667eea;
        margin: 1rem 0;
    }
    .recommendation-critical {
        background-color: #ffe6e6;
        padding: 1rem;
        border-left: 4px solid #ff4444;
        margin: 1rem 0;
        border-radius: 0.25rem;
    }
    .recommendation-important {
        background-color: #fff9e6;
        padding: 1rem;
        border-left: 4px solid #ffbb33;
        margin: 1rem 0;
        border-radius: 0.25rem;
    }
</style>
""", unsafe_allow_html=True)


class InstrumentSeparator:
    """å‘¨æ³¢æ•°ãƒ™ãƒ¼ã‚¹éŸ³æºåˆ†é›¢"""
    
    def __init__(self, y, sr):
        self.y = y
        self.sr = sr
        self.y_mono = librosa.to_mono(y) if len(y.shape) > 1 else y
        
    def separate(self):
        """å…¨æ¥½å™¨ã‚’åˆ†é›¢"""
        
        stems = {}
        confidence = {}
        
        with st.spinner('ğŸ¸ æ¥½å™¨ã‚’åˆ†é›¢ä¸­...'):
            # ãƒœãƒ¼ã‚«ãƒ«
            stems['vocal'], confidence['vocal'] = self._extract_vocal()
            
            # ã‚­ãƒƒã‚¯
            stems['kick'], confidence['kick'] = self._extract_kick()
            
            # ã‚¹ãƒã‚¢
            stems['snare'], confidence['snare'] = self._extract_snare()
            
            # ãƒã‚¤ãƒãƒƒãƒˆ
            stems['hihat'], confidence['hihat'] = self._extract_hihat()
            
            # ãƒ™ãƒ¼ã‚¹
            stems['bass'], confidence['bass'] = self._extract_bass()
            
            # ã‚®ã‚¿ãƒ¼/ãã®ä»–
            stems['other'], confidence['other'] = self._extract_other()
        
        return stems, confidence
    
    def _extract_vocal(self):
        """ãƒœãƒ¼ã‚«ãƒ«æŠ½å‡º"""
        
        # ãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆæ¤œå‡ºï¼ˆ200-600HzåŸºéŸ³ã€1-4kHzãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆï¼‰
        # ã‚»ãƒ³ã‚¿ãƒ¼å®šä½
        
        # ãƒãƒ³ãƒ‰ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆ200-5000Hzï¼‰
        sos_low = signal.butter(4, 200 / (self.sr/2), btype='highpass', output='sos')
        sos_high = signal.butter(4, 5000 / (self.sr/2), btype='lowpass', output='sos')
        
        vocal_filtered = signal.sosfilt(sos_low, self.y_mono)
        vocal_filtered = signal.sosfilt(sos_high, vocal_filtered)
        
        # ãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆé ˜åŸŸã®å¼·èª¿
        D = librosa.stft(vocal_filtered)
        freqs = librosa.fft_frequencies(sr=self.sr)
        
        # 1-4kHzï¼ˆãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆï¼‰ã‚’å¼·èª¿
        formant_mask = (freqs >= 1000) & (freqs <= 4000)
        D[formant_mask, :] *= 2.0
        
        vocal = librosa.istft(D)
        
        # ä¿¡é ¼åº¦è¨ˆç®—ï¼ˆãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆé ˜åŸŸã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰
        formant_energy = np.mean(np.abs(D[formant_mask, :]))
        total_energy = np.mean(np.abs(D))
        confidence = min(formant_energy / (total_energy + 1e-10), 1.0)
        
        return vocal, confidence
    
    def _extract_kick(self):
        """ã‚­ãƒƒã‚¯æŠ½å‡º"""
        
        # 40-120Hz + ãƒˆãƒ©ãƒ³ã‚¸ã‚§ãƒ³ãƒˆæ¤œå‡º
        
        # ãƒãƒ³ãƒ‰ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        sos = signal.butter(4, [40 / (self.sr/2), 120 / (self.sr/2)], 
                           btype='bandpass', output='sos')
        kick_filtered = signal.sosfilt(sos, self.y_mono)
        
        # ãƒˆãƒ©ãƒ³ã‚¸ã‚§ãƒ³ãƒˆæ¤œå‡º
        onset_env = librosa.onset.onset_strength(y=self.y_mono, sr=self.sr)
        onset_frames = librosa.onset.onset_detect(y=self.y_mono, sr=self.sr, 
                                                   units='frames')
        
        # ã‚­ãƒƒã‚¯ã¯ä½åŸŸ + å¼·ã„ãƒˆãƒ©ãƒ³ã‚¸ã‚§ãƒ³ãƒˆ
        kick_enhanced = kick_filtered.copy()
        
        # ã‚ªãƒ³ã‚»ãƒƒãƒˆæ™‚åˆ»ã§å¼·èª¿
        hop_length = 512
        for frame in onset_frames:
            sample = frame * hop_length
            if sample < len(kick_enhanced):
                # ã‚ªãƒ³ã‚»ãƒƒãƒˆå‰å¾Œã‚’å¼·èª¿
                start = max(0, sample - 1000)
                end = min(len(kick_enhanced), sample + 2000)
                kick_enhanced[start:end] *= 1.5
        
        # ä¿¡é ¼åº¦ï¼ˆä½åŸŸã‚¨ãƒãƒ«ã‚®ãƒ¼ + ãƒˆãƒ©ãƒ³ã‚¸ã‚§ãƒ³ãƒˆé »åº¦ï¼‰
        low_energy = np.sqrt(np.mean(kick_filtered**2))
        onset_density = len(onset_frames) / (len(self.y_mono) / self.sr)
        confidence = min((low_energy * 10 + onset_density / 2) / 2, 1.0)
        
        return kick_enhanced, confidence
    
    def _extract_snare(self):
        """ã‚¹ãƒã‚¢æŠ½å‡º"""
        
        # 200-400Hzï¼ˆãƒœãƒ‡ã‚£ï¼‰+ 2-5kHzï¼ˆã‚¢ã‚¿ãƒƒã‚¯ï¼‰
        
        # è¤‡æ•°å¸¯åŸŸã®çµ„ã¿åˆã‚ã›
        sos_body = signal.butter(4, [200 / (self.sr/2), 400 / (self.sr/2)], 
                                btype='bandpass', output='sos')
        sos_attack = signal.butter(4, [2000 / (self.sr/2), 5000 / (self.sr/2)], 
                                  btype='bandpass', output='sos')
        
        snare_body = signal.sosfilt(sos_body, self.y_mono)
        snare_attack = signal.sosfilt(sos_attack, self.y_mono)
        
        # åˆæˆ
        snare = snare_body * 0.6 + snare_attack * 0.4
        
        # ãƒˆãƒ©ãƒ³ã‚¸ã‚§ãƒ³ãƒˆæ¤œå‡ºï¼ˆã‚­ãƒƒã‚¯ã‚ˆã‚Šé‹­ã„ï¼‰
        onset_env = librosa.onset.onset_strength(y=self.y_mono, sr=self.sr, 
                                                 aggregate=np.median)
        
        confidence = 0.7  # ä¸­ç¨‹åº¦ã®ä¿¡é ¼åº¦
        
        return snare, confidence
    
    def _extract_hihat(self):
        """ãƒã‚¤ãƒãƒƒãƒˆæŠ½å‡º"""
        
        # 6-15kHz + é€£ç¶šãƒˆãƒ©ãƒ³ã‚¸ã‚§ãƒ³ãƒˆ
        
        sos = signal.butter(4, 6000 / (self.sr/2), btype='highpass', output='sos')
        hihat = signal.sosfilt(sos, self.y_mono)
        
        # é«˜åŸŸã®ã¿ãªã®ã§ä¿¡é ¼åº¦ã¯ä¸­ç¨‹åº¦
        high_energy = np.sqrt(np.mean(hihat**2))
        confidence = min(high_energy * 20, 0.8)
        
        return hihat, confidence
    
    def _extract_bass(self):
        """ãƒ™ãƒ¼ã‚¹æŠ½å‡º"""
        
        # 60-250Hz + æŒç¶šéŸ³ï¼ˆãƒˆãƒ©ãƒ³ã‚¸ã‚§ãƒ³ãƒˆå°‘ãªã„ï¼‰
        
        sos = signal.butter(4, [60 / (self.sr/2), 250 / (self.sr/2)], 
                           btype='bandpass', output='sos')
        bass = signal.sosfilt(sos, self.y_mono)
        
        # ã‚­ãƒƒã‚¯ã¨å·®åˆ†ï¼ˆã‚­ãƒƒã‚¯ã¯ãƒˆãƒ©ãƒ³ã‚¸ã‚§ãƒ³ãƒˆã€ãƒ™ãƒ¼ã‚¹ã¯æŒç¶šï¼‰
        # RMSè¨ˆç®—
        frame_length = self.sr // 2
        hop_length = self.sr // 4
        rms = librosa.feature.rms(y=bass, frame_length=frame_length, 
                                 hop_length=hop_length)[0]
        
        # æŒç¶šæ€§ï¼ˆRMSã®åˆ†æ•£ãŒå°ã•ã„ = æŒç¶šéŸ³ï¼‰
        rms_variance = np.var(rms)
        confidence = min(1.0 / (rms_variance + 0.1), 0.9)
        
        return bass, confidence
    
    def _extract_other(self):
        """ã‚®ã‚¿ãƒ¼/ãã®ä»–"""
        
        # ä¸­åŸŸï¼ˆ300-2000Hzï¼‰
        
        sos = signal.butter(4, [300 / (self.sr/2), 2000 / (self.sr/2)], 
                           btype='bandpass', output='sos')
        other = signal.sosfilt(sos, self.y_mono)
        
        confidence = 0.6  # æ¨å®š
        
        return other, confidence


class InstrumentAnalyzer:
    """æ¥½å™¨åˆ¥è©³ç´°è§£æ"""
    
    def __init__(self, stems, sr, full_audio):
        self.stems = stems
        self.sr = sr
        self.full_audio = full_audio
        
    def analyze_all(self):
        """å…¨æ¥½å™¨ã‚’è§£æ"""
        
        analyses = {}
        
        for instrument, audio in self.stems.items():
            if audio is not None and len(audio) > 0:
                analyses[instrument] = self.analyze_instrument(instrument, audio)
        
        return analyses
    
    def analyze_instrument(self, name, audio):
        """å€‹åˆ¥æ¥½å™¨ã®è§£æ"""
        
        analysis = {
            'name': name,
            'present': True,
            'level_rms': self._calculate_rms(audio),
            'level_peak': self._calculate_peak(audio),
            'crest_factor': 0,
            'frequency_profile': {},
            'issues': [],
            'recommendations': []
        }
        
        # ã‚¯ãƒ¬ã‚¹ãƒˆãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼
        if analysis['level_rms'] > -100:
            analysis['crest_factor'] = analysis['level_peak'] - analysis['level_rms']
        
        # æ¥½å™¨åˆ¥ã®è©³ç´°è§£æ
        if name == 'vocal':
            analysis.update(self._analyze_vocal(audio))
        elif name == 'kick':
            analysis.update(self._analyze_kick(audio))
        elif name == 'snare':
            analysis.update(self._analyze_snare(audio))
        elif name == 'bass':
            analysis.update(self._analyze_bass(audio))
        elif name == 'hihat':
            analysis.update(self._analyze_hihat(audio))
        elif name == 'other':
            analysis.update(self._analyze_other(audio))
        
        return analysis
    
    def _calculate_rms(self, audio):
        """RMSè¨ˆç®—"""
        rms = np.sqrt(np.mean(audio**2))
        return 20 * np.log10(rms) if rms > 0 else -100
    
    def _calculate_peak(self, audio):
        """ãƒ”ãƒ¼ã‚¯è¨ˆç®—"""
        peak = np.max(np.abs(audio))
        return 20 * np.log10(peak) if peak > 0 else -100
    
    def _analyze_vocal(self, audio):
        """ãƒœãƒ¼ã‚«ãƒ«è©³ç´°è§£æ"""
        
        D = np.abs(librosa.stft(audio))
        freqs = librosa.fft_frequencies(sr=self.sr)
        spectrum = np.mean(D, axis=1)
        
        # åŸºéŸ³å¸¯åŸŸï¼ˆ150-400Hzï¼‰
        fundamental_mask = (freqs >= 150) & (freqs < 400)
        fundamental_level = 20 * np.log10(np.mean(spectrum[fundamental_mask]) + 1e-10)
        
        # æ˜ç­åº¦å¸¯åŸŸï¼ˆ2-4kHzï¼‰
        clarity_mask = (freqs >= 2000) & (freqs < 4000)
        clarity_level = 20 * np.log10(np.mean(spectrum[clarity_mask]) + 1e-10)
        
        # ç©ºæ°—æ„Ÿï¼ˆ8-12kHzï¼‰
        air_mask = (freqs >= 8000) & (freqs < 12000)
        air_level = 20 * np.log10(np.mean(spectrum[air_mask]) + 1e-10)
        
        return {
            'frequency_profile': {
                'fundamental': fundamental_level,
                'clarity': clarity_level,
                'air': air_level
            },
            'formants_detected': True
        }
    
    def _analyze_kick(self, audio):
        """ã‚­ãƒƒã‚¯è©³ç´°è§£æ"""
        
        D = np.abs(librosa.stft(audio))
        freqs = librosa.fft_frequencies(sr=self.sr)
        spectrum = np.mean(D, axis=1)
        
        # ã‚¢ã‚¿ãƒƒã‚¯å‘¨æ³¢æ•°ï¼ˆ60-100Hzï¼‰
        attack_mask = (freqs >= 60) & (freqs < 100)
        attack_level = 20 * np.log10(np.mean(spectrum[attack_mask]) + 1e-10)
        
        # ãƒ“ãƒ¼ã‚¿ãƒ¼éŸ³ï¼ˆ2-5kHzï¼‰
        beater_mask = (freqs >= 2000) & (freqs < 5000)
        beater_level = 20 * np.log10(np.mean(spectrum[beater_mask]) + 1e-10)
        
        # ã‚µãƒ–ã‚½ãƒ‹ãƒƒã‚¯ï¼ˆ<40Hzï¼‰
        subsonic_mask = freqs < 40
        subsonic_level = 20 * np.log10(np.mean(spectrum[subsonic_mask]) + 1e-10)
        
        return {
            'frequency_profile': {
                'attack': attack_level,
                'beater': beater_level,
                'subsonic': subsonic_level
            }
        }
    
    def _analyze_snare(self, audio):
        """ã‚¹ãƒã‚¢è©³ç´°è§£æ"""
        
        D = np.abs(librosa.stft(audio))
        freqs = librosa.fft_frequencies(sr=self.sr)
        spectrum = np.mean(D, axis=1)
        
        # ãƒœãƒ‡ã‚£ï¼ˆ200-400Hzï¼‰
        body_mask = (freqs >= 200) & (freqs < 400)
        body_level = 20 * np.log10(np.mean(spectrum[body_mask]) + 1e-10)
        
        # ã‚¢ã‚¿ãƒƒã‚¯ï¼ˆ2-5kHzï¼‰
        attack_mask = (freqs >= 2000) & (freqs < 5000)
        attack_level = 20 * np.log10(np.mean(spectrum[attack_mask]) + 1e-10)
        
        # ã‚¹ãƒŠãƒƒãƒ”ãƒ¼ï¼ˆ6-10kHzï¼‰
        snappy_mask = (freqs >= 6000) & (freqs < 10000)
        snappy_level = 20 * np.log10(np.mean(spectrum[snappy_mask]) + 1e-10)
        
        return {
            'frequency_profile': {
                'body': body_level,
                'attack': attack_level,
                'snappy': snappy_level
            }
        }
    
    def _analyze_bass(self, audio):
        """ãƒ™ãƒ¼ã‚¹è©³ç´°è§£æ"""
        
        D = np.abs(librosa.stft(audio))
        freqs = librosa.fft_frequencies(sr=self.sr)
        spectrum = np.mean(D, axis=1)
        
        # åŸºéŸ³ï¼ˆ80-200Hzï¼‰
        fundamental_mask = (freqs >= 80) & (freqs < 200)
        fundamental_level = 20 * np.log10(np.mean(spectrum[fundamental_mask]) + 1e-10)
        
        # å€éŸ³ï¼ˆ200-800Hzï¼‰
        harmonic_mask = (freqs >= 200) & (freqs < 800)
        harmonic_level = 20 * np.log10(np.mean(spectrum[harmonic_mask]) + 1e-10)
        
        # ã‚¢ã‚¿ãƒƒã‚¯ï¼ˆ1-3kHzï¼‰
        attack_mask = (freqs >= 1000) & (freqs < 3000)
        attack_level = 20 * np.log10(np.mean(spectrum[attack_mask]) + 1e-10)
        
        return {
            'frequency_profile': {
                'fundamental': fundamental_level,
                'harmonic': harmonic_level,
                'attack': attack_level
            }
        }
    
    def _analyze_hihat(self, audio):
        """ãƒã‚¤ãƒãƒƒãƒˆè§£æ"""
        return {'frequency_profile': {}}
    
    def _analyze_other(self, audio):
        """ãã®ä»–è§£æ"""
        return {'frequency_profile': {}}


class DetailedRecommendationGenerator:
    """è¶…è©³ç´°ãªæ”¹å–„ææ¡ˆç”Ÿæˆ"""
    
    def __init__(self, instrument_analyses, mix_type, venue_info, mixer_name=''):
        self.analyses = instrument_analyses
        self.mix_type = mix_type
        self.venue_info = venue_info
        self.mixer_name = mixer_name
        
    def generate_all(self):
        """å…¨æ¥½å™¨ã®ææ¡ˆç”Ÿæˆ"""
        
        recommendations = []
        
        # å„ªå…ˆé †ä½: ãƒœãƒ¼ã‚«ãƒ« > ã‚­ãƒƒã‚¯ > ãƒ™ãƒ¼ã‚¹ > ã‚¹ãƒã‚¢ > ãã®ä»–
        priority_order = ['vocal', 'kick', 'bass', 'snare', 'hihat', 'other']
        
        for instrument in priority_order:
            if instrument in self.analyses:
                rec = self.generate_for_instrument(instrument, self.analyses[instrument])
                if rec:
                    recommendations.append(rec)
        
        return recommendations
    
    def generate_for_instrument(self, name, analysis):
        """æ¥½å™¨åˆ¥ã®è©³ç´°ææ¡ˆ"""
        
        if name == 'vocal':
            return self._recommend_vocal(analysis)
        elif name == 'kick':
            return self._recommend_kick(analysis)
        elif name == 'bass':
            return self._recommend_bass(analysis)
        elif name == 'snare':
            return self._recommend_snare(analysis)
        else:
            return None
    
    def _recommend_vocal(self, analysis):
        """ãƒœãƒ¼ã‚«ãƒ«ææ¡ˆ"""
        
        rec = {
            'instrument': 'ãƒœãƒ¼ã‚«ãƒ«',
            'priority': 'critical',
            'icon': 'ğŸ¤',
            'current_state': {},
            'issues': [],
            'solutions': [],
            'expected_results': []
        }
        
        # ç¾çŠ¶
        rec['current_state'] = {
            'level': f"{analysis['level_rms']:.1f} dBFS",
            'fundamental': f"{analysis['frequency_profile'].get('fundamental', -100):.1f} dB",
            'clarity': f"{analysis['frequency_profile'].get('clarity', -100):.1f} dB",
            'air': f"{analysis['frequency_profile'].get('air', -100):.1f} dB"
        }
        
        # å•é¡Œæ¤œå‡º
        clarity_level = analysis['frequency_profile'].get('clarity', -100)
        
        if clarity_level < -30:
            rec['issues'].append({
                'problem': 'æ˜ç­åº¦ãŒæ¥µã‚ã¦ä½ã„',
                'severity': 'critical',
                'detail': f'2-4kHzå¸¯åŸŸãŒ {clarity_level:.1f}dBï¼ˆæ¨å¥¨: -20dBä»¥ä¸Šï¼‰'
            })
            
            # è§£æ±ºç­–
            rec['solutions'].append({
                'title': 'PEQè¨­å®šï¼ˆæ˜ç­åº¦å‘ä¸Šï¼‰',
                'steps': [
                    'Band 1: 3.2kHz, Q=2.0, +4.0dB',
                    'Band 2: 5kHz, Q=1.5, +2.5dB',
                    'åŠ¹æœ: å­éŸ³ãƒ»æ˜ç­åº¦ã®å¤§å¹…å‘ä¸Š'
                ],
                'mixer_specific': self._get_mixer_eq_instructions('vocal_clarity')
            })
            
            rec['expected_results'].append('æ˜ç­åº¦ +60%')
            rec['expected_results'].append('æ­Œè©ã®è´ãå–ã‚Šã‚„ã™ã•å¤§å¹…æ”¹å–„')
        
        # ãƒ¬ãƒ™ãƒ«ãƒã‚§ãƒƒã‚¯
        if analysis['level_rms'] < -30:
            rec['issues'].append({
                'problem': 'ãƒ¬ãƒ™ãƒ«ãŒä½ã™ãã‚‹',
                'severity': 'high',
                'detail': f'RMS {analysis["level_rms"]:.1f}dBFS'
            })
            
            rec['solutions'].append({
                'title': 'Faderèª¿æ•´ + Compressor',
                'steps': [
                    f'Fader: ç¾åœ¨ä½ç½®ã‹ã‚‰ +{abs(analysis["level_rms"] + 25):.0f}dB',
                    'Compressor: Threshold -18dB, Ratio 4:1',
                    'Attack 10ms, Release 100ms',
                    'Make-up Gain: +3dB'
                ]
            })
        
        return rec
    
    def _recommend_kick(self, analysis):
        """ã‚­ãƒƒã‚¯ææ¡ˆ"""
        
        rec = {
            'instrument': 'ã‚­ãƒƒã‚¯',
            'priority': 'important',
            'icon': 'ğŸ¥',
            'current_state': {},
            'issues': [],
            'solutions': [],
            'expected_results': []
        }
        
        # ã‚µãƒ–ã‚½ãƒ‹ãƒƒã‚¯ãƒã‚§ãƒƒã‚¯
        subsonic = analysis['frequency_profile'].get('subsonic', -100)
        
        if subsonic > -40:
            rec['issues'].append({
                'problem': 'ã‚µãƒ–ã‚½ãƒ‹ãƒƒã‚¯æˆåˆ†æ¤œå‡º',
                'severity': 'critical',
                'detail': f'40Hzä»¥ä¸‹: {subsonic:.1f}dB'
            })
            
            rec['solutions'].append({
                'title': 'HPFè¨­å®šï¼ˆå¿…é ˆï¼‰',
                'steps': [
                    'HPF: 35Hz, 24dB/oct',
                    'ç†ç”±: ãƒ˜ãƒƒãƒ‰ãƒ«ãƒ¼ãƒ ç¢ºä¿ã€ã‚·ã‚¹ãƒ†ãƒ ä¿è­·',
                    'åŠ¹æœ: +2ã€œ3dB ã®ãƒ˜ãƒƒãƒ‰ãƒ«ãƒ¼ãƒ '
                ]
            })
            
            rec['expected_results'].append('ãƒ˜ãƒƒãƒ‰ãƒ«ãƒ¼ãƒ  +2ã€œ3dB')
            rec['expected_results'].append('ã‚·ã‚¹ãƒ†ãƒ è² è·è»½æ¸›')
        
        return rec
    
    def _recommend_bass(self, analysis):
        """ãƒ™ãƒ¼ã‚¹ææ¡ˆ"""
        
        rec = {
            'instrument': 'ãƒ™ãƒ¼ã‚¹',
            'priority': 'important',
            'icon': 'ğŸ¸',
            'current_state': {},
            'issues': [],
            'solutions': [],
            'expected_results': []
        }
        
        # åŸºæœ¬æƒ…å ±
        rec['current_state'] = {
            'level': f"{analysis['level_rms']:.1f} dBFS",
            'fundamental': f"{analysis['frequency_profile'].get('fundamental', -100):.1f} dB"
        }
        
        return rec
    
    def _recommend_snare(self, analysis):
        """ã‚¹ãƒã‚¢ææ¡ˆ"""
        
        rec = {
            'instrument': 'ã‚¹ãƒã‚¢',
            'priority': 'optional',
            'icon': 'ğŸ¥',
            'current_state': {},
            'issues': [],
            'solutions': [],
            'expected_results': []
        }
        
        return rec
    
    def _get_mixer_eq_instructions(self, goal):
        """ãƒŸã‚­ã‚µãƒ¼å›ºæœ‰ã®æ“ä½œæ‰‹é †ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        
        # TODO: Phase 2ã§Webæ¤œç´¢ã‹ã‚‰å–å¾—
        
        if 'CL' in self.mixer_name.upper() or 'QL' in self.mixer_name.upper():
            return {
                'mixer': 'Yamaha CL/QL Series',
                'steps': [
                    '1. ãƒãƒ£ãƒ³ãƒãƒ«ã‚’é¸æŠ',
                    '2. [EQ]ãƒœã‚¿ãƒ³ â†’ PEQç”»é¢',
                    '3. ä¸Šè¨˜ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š',
                    '4. EQ ON ã‚’ç¢ºèª'
                ]
            }
        elif 'X32' in self.mixer_name.upper():
            return {
                'mixer': 'Behringer X32',
                'steps': [
                    '1. ãƒãƒ£ãƒ³ãƒãƒ«ã‚’é¸æŠ',
                    '2. [EQ]ãƒœã‚¿ãƒ³',
                    '3. ä¸Šè¨˜ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š',
                    'æ³¨æ„: 4ãƒãƒ³ãƒ‰ã®ã¿ã€‚å„ªå…ˆé †ä½ã‚’æ±ºã‚ã¦ä½¿ç”¨'
                ]
            }
        else:
            return {
                'mixer': 'ä¸€èˆ¬çš„ãªæ‰‹é †',
                'steps': [
                    '1. ãƒãƒ£ãƒ³ãƒãƒ«EQã‚’é–‹ã',
                    '2. ä¸Šè¨˜ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š'
                ]
            }


# Streamlit UIéƒ¨åˆ†ã¯æ—¢å­˜ã®V2ã¨é¡ä¼¼
# ã“ã“ã§ã¯ä¸»è¦ãªè§£æãƒ­ã‚¸ãƒƒã‚¯ã®ã¿å®Ÿè£…

def main():
    st.markdown('<h1 class="main-header">ğŸ›ï¸ Live PA Audio Analyzer V3.0</h1>', 
                unsafe_allow_html=True)
    st.markdown('<p class="version-badge">Alpha Release - æ¥½å™¨åˆ¥è©³ç´°è§£æå¯¾å¿œ</p>', 
                unsafe_allow_html=True)
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        
        uploaded_file = st.file_uploader(
            "éŸ³æºãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=['mp3', 'wav', 'flac', 'm4a']
        )
        
        if uploaded_file:
            file_size_mb = uploaded_file.size / (1024 * 1024)
            if file_size_mb > 100:
                st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤§ãã™ãã¾ã™ï¼ˆ{file_size_mb:.1f}MBï¼‰")
                uploaded_file = None
            else:
                st.success(f"âœ“ {file_size_mb:.1f}MB")
        
        st.markdown("---")
        st.subheader("ğŸ›ï¸ ä¼šå ´æƒ…å ±")
        
        venue_capacity = st.slider("ä¼šå ´ã‚­ãƒ£ãƒ‘ï¼ˆäººï¼‰", 50, 2000, 150, 50)
        stage_volume = st.selectbox("ã‚¹ãƒ†ãƒ¼ã‚¸ç”ŸéŸ³", ['high', 'medium', 'low', 'none'], 1)
        
        mixer_name = st.text_input("ãƒŸã‚­ã‚µãƒ¼", placeholder="ä¾‹: Yamaha CL5")
        pa_system = st.text_input("PA", placeholder="ä¾‹: d&b V-Series")
        
        st.markdown("---")
        analyze_button = st.button("ğŸš€ è§£æé–‹å§‹", type="primary", use_container_width=True)
    
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
    if uploaded_file is None:
        st.info("ğŸ‘ˆ éŸ³æºã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
        
        st.markdown("### ğŸ†• V3.0 Alpha ã®æ–°æ©Ÿèƒ½")
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            **ğŸ¸ æ¥½å™¨åˆ¥è§£æ**
            - ãƒœãƒ¼ã‚«ãƒ«ã€ãƒ‰ãƒ©ãƒ ã€ãƒ™ãƒ¼ã‚¹ã‚’å€‹åˆ¥ã«åˆ†æ
            - å„æ¥½å™¨ã®å‘¨æ³¢æ•°ç‰¹æ€§ã‚’è©³ç´°è§£æ
            - æ¥½å™¨é–“ã®å¹²æ¸‰ã‚’æ¤œå‡º
            """)
        
        with col2:
            st.markdown("""
            **ğŸ’¡ è¶…è©³ç´°ãªæ”¹å–„ææ¡ˆ**
            - å…·ä½“çš„ãªEQè¨­å®šå€¤
            - ãƒŸã‚­ã‚µãƒ¼å›ºæœ‰ã®æ“ä½œæ‰‹é †
            - æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœã¾ã§æ˜è¨˜
            """)
    
    elif analyze_button:
        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp:
            tmp.write(uploaded_file.getvalue())
            tmp_path = tmp.name
        
        try:
            # éŸ³æºèª­ã¿è¾¼ã¿
            with st.spinner('ğŸµ éŸ³æºã‚’èª­ã¿è¾¼ã¿ä¸­...'):
                y, sr = librosa.load(tmp_path, sr=22050, mono=False, duration=300)
                
                if len(y.shape) == 1:
                    y = np.array([y, y])
            
            st.success("âœ… èª­ã¿è¾¼ã¿å®Œäº†")
            
            # æ¥½å™¨åˆ†é›¢
            separator = InstrumentSeparator(y, sr)
            stems, confidence = separator.separate()
            
            st.success("âœ… æ¥½å™¨åˆ†é›¢å®Œäº†")
            
            # æ¥½å™¨æ¤œå‡ºçµæœè¡¨ç¤º
            st.markdown("## ğŸ” æ¤œå‡ºã•ã‚ŒãŸæ¥½å™¨")
            
            cols = st.columns(3)
            detected = [(name, conf) for name, conf in confidence.items() if conf > 0.5]
            detected.sort(key=lambda x: x[1], reverse=True)
            
            for i, (name, conf) in enumerate(detected):
                col_idx = i % 3
                with cols[col_idx]:
                    icon = {'vocal': 'ğŸ¤', 'kick': 'ğŸ¥', 'snare': 'ğŸ¥', 
                           'bass': 'ğŸ¸', 'hihat': 'ğŸ¥', 'other': 'ğŸ¹'}.get(name, 'ğŸµ')
                    name_ja = {'vocal': 'ãƒœãƒ¼ã‚«ãƒ«', 'kick': 'ã‚­ãƒƒã‚¯', 'snare': 'ã‚¹ãƒã‚¢',
                              'bass': 'ãƒ™ãƒ¼ã‚¹', 'hihat': 'ãƒã‚¤ãƒãƒƒãƒˆ', 'other': 'ãã®ä»–'}.get(name, name)
                    st.metric(f"{icon} {name_ja}", f"{conf*100:.0f}%", 
                             delta="æ¤œå‡º" if conf > 0.7 else "æ¨å®š")
            
            st.markdown("---")
            
            # æ¥½å™¨åˆ¥è§£æ
            analyzer = InstrumentAnalyzer(stems, sr, y)
            analyses = analyzer.analyze_all()
            
            st.success("âœ… è©³ç´°è§£æå®Œäº†")
            
            # æ”¹å–„ææ¡ˆç”Ÿæˆ
            rec_gen = DetailedRecommendationGenerator(
                analyses, 'live', 
                {'capacity': venue_capacity, 'stage_volume': stage_volume},
                mixer_name
            )
            recommendations = rec_gen.generate_all()
            
            # ææ¡ˆè¡¨ç¤º
            st.markdown("## ğŸ’¡ æ¥½å™¨åˆ¥æ”¹å–„ææ¡ˆ")
            
            for rec in recommendations:
                priority_color = {
                    'critical': 'ğŸ”´',
                    'important': 'ğŸŸ¡',
                    'optional': 'ğŸŸ¢'
                }.get(rec['priority'], 'âšª')
                
                with st.expander(f"{priority_color} {rec['icon']} {rec['instrument']}", 
                               expanded=(rec['priority'] == 'critical')):
                    
                    # ç¾çŠ¶
                    if rec['current_state']:
                        st.markdown("**ç¾çŠ¶:**")
                        for key, value in rec['current_state'].items():
                            st.write(f"- {key}: {value}")
                    
                    # å•é¡Œç‚¹
                    if rec['issues']:
                        st.markdown("**âŒ å•é¡Œç‚¹:**")
                        for issue in rec['issues']:
                            severity_icon = {'critical': 'ğŸ”´', 'high': 'ğŸŸ¡', 'medium': 'ğŸŸ '}.get(issue['severity'], 'âšª')
                            st.write(f"{severity_icon} {issue['problem']}")
                            st.caption(issue['detail'])
                    
                    # è§£æ±ºç­–
                    if rec['solutions']:
                        st.markdown("**âœ… è§£æ±ºç­–:**")
                        for i, sol in enumerate(rec['solutions'], 1):
                            st.markdown(f"**{i}. {sol['title']}**")
                            for step in sol['steps']:
                                st.write(f"  - {step}")
                            
                            if sol.get('mixer_specific'):
                                with st.expander(f"ğŸ“± {sol['mixer_specific']['mixer']} ã§ã®æ“ä½œ"):
                                    for step in sol['mixer_specific']['steps']:
                                        st.write(step)
                    
                    # æœŸå¾…ã•ã‚Œã‚‹çµæœ
                    if rec['expected_results']:
                        st.markdown("**ğŸ¯ æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ:**")
                        for result in rec['expected_results']:
                            st.write(f"âœ… {result}")
            
        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            with st.expander("è©³ç´°"):
                st.exception(e)
        
        finally:
            import os
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)


if __name__ == "__main__":
    main()
